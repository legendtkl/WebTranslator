<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Context-Aware Translation Test</title>
</head>
<body>
    <h1>Mathematical Formula Test</h1>
    
    <div class="content">
        <p>The color transformation can be calculated using the following formula:</p>
        <p>(0.10 * -0.17 + 0.12 * 0.39 - 0.36 * 0.1) * R + (-0.29 * -0.17 - 0.05 * 0.39 - 0.21 * 0.1) * G + (0.05 * -0.17 + 0.27 * 0.39 + 0.14 * 0.1) * B</p>
        <p>And so on for the remaining color channels.</p>
    </div>
    
    <div class="section">
        <h2>Sequential Content</h2>
        <p>First, we initialize the variables.</p>
        <p>Then, we apply the transformation matrix.</p>
        <p>Finally, we normalize the output values.</p>
    </div>
    
    <div class="math-example">
        <p>Consider the equation: x² + 2x - 3 = 0</p>
        <p>The solution can be found using the quadratic formula.</p>
        <p>Therefore, x = (-2 ± √(4 + 12)) / 2 = (-2 ± 4) / 2</p>
        <p>Hence, x = 1 or x = -3</p>
    </div>
    
    <div class="self-attention-example">
        <p>Self attention does something like adding up the embedding vectors for each of the words, but instead of directly adding them up it applies some weights to each. So if the embedding vectors for humpty,dumpty, sat are x1, x2, x3 respectively, then it will multiply each one with a weight (a number) before adding them up. Something like output = 0.5 x1 + 0.25 x2 + 0.25 x3 where output is the self-attention output.</p>
        <p>其中 output 就是自注意力的输出。</p>
        <p>Ideally, we want these weights to be dependent on the vector we are adding.</p>
    </div>
    
    <div class="list-example">
        <p>1. Open the configuration file</p>
        <p>2. Modify the settings as needed</p>
        <p>3. Save and restart the application</p>
    </div>
</body>
</html>